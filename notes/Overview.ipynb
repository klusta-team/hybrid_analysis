{
 "metadata": {
  "name": "Overview"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Original data files\n",
      "There is a folder consisting of the three recordings (.dat files) of Mariano Belluscio. One .dat file has been clustered (`n6mab031109.dat`), with method `MKKdistfloat` and has a number of nice clusters out of which we can choose a few suitable donor cells. \n",
      "\n",
      "#Hybrid dataset creation\n",
      "\n",
      "Minimal information necessary for defining a hybrid dataset is a 4-tuple of the form: $\\mbox{(acceptor, donor_id, amplitude, time_series)}$, where `acceptor` is the dataset which receives spikes from another analogously recorded dataset `donor` at the times specified by `time_series`.\n",
      "Each element of the 4-tuple may be generated by a range of other parameters, e.g.\n",
      "\n",
      "1) A rate, $r$ could define a `time_series` consisting of regular spiking at $r$ Hz.\n",
      "\n",
      "2) The donor_id could be derived from information, e.g. the 3-tuple $\\mbox{(donor,donorcluid,donorcluster)}$ pertaining to the donor dataset (donor), the detection method and clustering algorithm (donorcluid) and cluster (donorcluster) number of the cell that is added to the acceptor dataset.\n",
      "    def: create_donor_id(donor,donorcluid,donorcluster):\n",
      "    \n",
      "    output: \n",
      "    donor_id = donor_donorcluid_donorcluster, (which typically looks like: `n6mab031109_MKKdistfloat_54`).\n",
      "    meanspike_file_id = a file called donor_id.msua.1\n",
      "    meanmask_file = a file called donor_id.amsk.1\n",
      "    \n",
      "We can have a folder containing donor_ids, or a list of 3-tuples generating to donor_ids.   \n",
      "    \n",
      "We can create a hybrid dataset $D_{\\mbox{(acceptor, donor_id, amplitude, time_series)}}$ using the Python function:\n",
      "    def: create_hybrid_datfile(acceptor, donor_id, amplitude, time_series):\n",
      "        \n",
      "This function outputs a raw datafile called, $\\mathcal{H}_{\\mbox{(acceptor, donor_id, amplitude, time_series)}}$.dat, where $\\mathcal{H}_{\\mbox{var}}$ is the hash produced from the variables `var` via some hash function.     \n",
      "    \n",
      "Question: The raw waveform from one recording on non-relevant channels could contain wildly inappropriate waveforms. I got around this before by only added parts of the wave form corresponding to the .amsk.1 file.    \n",
      "    \n",
      "#Running SpikeDetekt with various parameters\n",
      "\n",
      "We aim to find the optimal detection strategy, but running spikedetekt on $\\mathcal{H}_{\\mbox{(acceptor, donor_id, amplitude, time_series)}}$.dat  several times using a variety of parameters, `params`, resulting in two files:\n",
      "\n",
      "$\\mathcal{H}_{\\mbox{(acceptor, donor_id, amplitude, time_series)}}$_$\\mathcal{H}_{\\mbox{ params}}$.kwx \n",
      "\n",
      "$\\mathcal{H}_{\\mbox{(acceptor, donor_id, amplitude, time_series)}}$_$\\mathcal{H}_{\\mbox{ params}}$.kwik\n",
      "    \n",
      "The parameters are stored in a global Python dictionary of  variables which can be accessed by all modules of SpikeDetekt.\n",
      "The default value of these parameters are stored in `spikedetekt/spikedetekt/defaultparameters.py`. \n",
      "\n",
      "We would like t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}