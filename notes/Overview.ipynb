{
 "metadata": {
  "name": "Overview"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Important Preliminaries:\n",
      "1). The .kwik format has to be modified so that it can store more than one clustering.\n",
      "\n",
      "2). Which hashing algorithm? Something from [http://docs.python.org/2/library/hashlib.html](http://docs.python.org/2/library/hashlib.html). \n",
      "We obviously don't need cryptography. \n",
      "\n",
      "#Original data files\n",
      "There is a folder consisting of the three recordings (.dat files) of Mariano Belluscio.\n",
      "One .dat file has been clustered (`n6mab031109.dat`), with method `MKKdistfloat` and has\n",
      "a number of nice clusters out of which we can choose a few suitable donor cells. There\n",
      "are two other recordings `n6mab041109.dat` and `n6mab061109.dat`; these will act as \n",
      "\"acceptor\" datasets.\n",
      "\n",
      "#Hybrid dataset creation\n",
      "\n",
      "Minimal information necessary for defining a hybrid dataset is a 4-tuple of the form:\n",
      "`(acceptor, donor_id, amplitude, time_series)`,\n",
      "where `acceptor` is the dataset which receives spikes from another analogously recorded\n",
      "dataset `donor` at the times specified by `time_series`.\n",
      "Each element of the 4-tuple may be generated by a range of other parameters, e.g.\n",
      "\n",
      "1) A rate, `r` could define a `time_series` consisting of regular spiking at `r` Hz.\n",
      "This could be created by a function:\n",
      "    \n",
      "    def: create_regular_resfile(rate, sampling_rate, starttime, endtime, resname):\n",
      "            '''Creates a regular .res file with firing rate r Hz\n",
      "          samples'''\n",
      "\n",
      "2) The donor_id could be derived from information, e.g. the 3-tuple \n",
      "(donor,donorcluid,donorcluster) pertaining to the donor dataset (donor),\n",
      "the detection method and clustering algorithm (donorcluid) and cluster (donorcluster)\n",
      "number of the cell that is added to the acceptor dataset.\n",
      "\n",
      "    def: create_donor_id(donor,donorcluid,donorcluster):\n",
      "    '''Outputs donor identity files: \n",
      "\n",
      "    donor_id = donor_donorcluid_donorcluster, (which typically looks like: n6mab031109_MKKdistfloat_54`).\n",
      "\n",
      "    meanspike_file_id = a file called donor_id.msua.1.\n",
      "\n",
      "    meanmask_file = a file called donor_id.amsk.1.'''\n",
      "    \n",
      "We can have a folder containing donor_ids, or a list of 3-tuples generating to donor_ids.   \n",
      "    \n",
      "We can create a hybrid dataset `D(acceptor, donor_id, amplitude, time_series)`\n",
      "(which we shall abbreviate to `D` when there is no ambiguity) using the Python function:\n",
      "    \n",
      "    def: create_hybrid_datfile(acceptor, donor_id, amplitude, time_series):\n",
      "        \n",
      "    '''This function outputs a raw datafile called, \n",
      "          Hash(D).dat, in the folder Hash(D)'''\n",
      "    \n",
      "    def: convert_to_kwik():\n",
      "            '''Converts Hash(D).dat to Hash(D).kwd and Hash(D).kwik'''\n",
      "    \n",
      ", where Hash(var) is the hash produced from the variables `var` via some\n",
      "hash function.     \n",
      "    \n",
      "Question: The raw waveform from one recording on non-relevant channels could contain\n",
      "wildly inappropriate waveforms. I got around this before\n",
      "by only added parts of the wave form corresponding to the .amsk.1 file.   \n",
      "\n",
      "NOTE: `D` implicitly contains the groundtruth times (equivalent to a .res and a .clu file) for the\n",
      "hybrid spike times and hybrid clusters.\n",
      "    \n",
      "#Running SpikeDetekt with various parameters\n",
      "\n",
      "We aim to find the optimal detection strategy, but running spikedetekt on Hash(D).dat\n",
      "several times using a variety of parameters, `params`,\n",
      "which we shall denote `p`, resulting in two files in the folder\n",
      "\n",
      "Hash(D)_Hash(p):\n",
      "    \n",
      "Hash(D)_Hash(p).kwx\n",
      "    \n",
      "Hash(D)_Hash(p).kwik\n",
      "    \n",
      "\n",
      "The feature and mask vectors, corresponding to the .fet and .fmask files are stored in the .kwx file,\n",
      "these will later be required by Masked KlustaKwik.\n",
      "\n",
      "The parameters are stored in a global Python dictionary of  variables which can be accessed by all modules of SpikeDetekt.\n",
      "The default value of these parameters are stored in `spikedetekt/spikedetekt/defaultparameters.py`. \n",
      "\n",
      "In the first phase we would like to finish testing the effect of varying certain parameters on the quality of spike detection and alignment,\n",
      "e.g. testing two-threshold detection by keeping the upper threshold constant and varying the lower threshold.\n",
      "We can vary one parameter and keep the others constant by specifying custom default parameters in the file `usualparameters.py`\n",
      ".  We will specify a 2D detection\n",
      "window, `Sigma` consisting of a minimal time jitter window and a threshold of minimal mask similarity measure (>0.8); a spike will be denoted\n",
      "as \"successfully detected\" if it lies within this detection window. This will be implemented in some Python functions in `evaluate_detection.py`.\n",
      "This will have two outputs: \n",
      "\n",
      "1) `detection_statistics(D, p,Sigma)` will be a set of scripts which will measure the efficacy of the detection `p`.\n",
      "e.g. we could have a function:\n",
      "    def: test_detection_algorithm(D,p,Sigma):\n",
      "            '''Test spike detection algorithm on a hybrid dataset'''\n",
      "\n",
      "2) A `derived groundtruth(D, p,Sigma)` relative to the detection (i.e. equivalent to a .clu file which is\n",
      " commensurate with the output .res file of detected spikes(those found in the window specified by `Sigma`,\n",
      " which specifies which spikes are background (in cluster 0) and which are hybrid\n",
      " (in clusters 1, 2, ... num_hybrids. This clustering can be stored in Hash(D)_Hash(p)_Sigma.kwik.\n",
      "  \n",
      "#Supervised Learning\n",
      "To perform supervised learning in the form of a support vector machine (SVM) on the groundtruth obtained after running SpikeDetekt\n",
      "and applying detection criterion `Sigma`, we use the Python machine learning package, `sklearn`. We will run SVM\n",
      "with a different kernels and their associated parameters, and a grid of class weights. We shall denote these parameters, s.\n",
      "The set of functions `supervised_learning` should output a set of clusterings from which we obtain an ROC curve, providing an \n",
      "upper bound for performance of any unsupervised algorithm. This set of clusterings will be stored in the file `(D, p,Sigma,s)`.kwik.\n",
      "                                                                                                                                                                                                                                                         \n",
      "\n",
      "#Clustering using Masked KlustaKwik\n",
      "Given detection, extraction of features and masking, specified in the files `Hash(D)_Hash(p).kwx`, we can now run\n",
      "KlustaKwik on the .fet and .fmask files obtained from `Hash(D)_Hash(p).kwx`. with a set of parameters which we shall denote `k` which will be defined a dictionary which will\n",
      "output a bash script for running KlustaKwik, \n",
      "\n",
      "    def: get_KK_input(D,p,k):\n",
      "    '''Will output the .fet and .fmask files in a folder, CartesianHash_(D,p,k)'''\n",
      "    \n",
      "    def: make_KK_runscripts(D,p,k):\n",
      "    '''Produces bash scripts pertaining to parameters k that run KlustaKwik on (D,p) '''\n",
      "    \n",
      "    def: make_bash_hash(D,p,k):\n",
      "    '''Outputs the hash of (D,p,k) and the bash script'''\n",
      "                                                                                                                                                                                                                                              \n",
      "                                                                                                                                                                                                                                              \n",
      "This will result in a clustering which will be stored in the file `Hash(D)_Hash(p)_Hash(k).kwx`. An analysis script can \n",
      "be run on `Hash(D)_Hash(p)_Hash(k).kwx` and the associated groundtruth, `Hash(D)_Hash(p)_Sigma.kwik` to obtain the \n",
      "confusion matrix. This will be stored as a pickle or a textfile `Hash(D)_Hash(p)_Hash(k).p`.\n",
      "                                                                                                                                                                                                                                              M#\n",
      "#Supercomputer\n",
      "Scripts will be required for sending jobs to Legion. These jobs will usually be SVM and Masked KlustaKwik.\n",
      "\n",
      "                                                                                                                                                                                                                                                         \n",
      "                                                                                                                                                                                                                                                         \n",
      "                                                                                                                                                                                                                                                         \n",
      "\n",
      "                                                                                                                                                                                                                                                         \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "                                                                                                                                                                                                                                                         \n",
      "                                                                                                                                                                                                                                                         \n",
      "                                                                                                                                                                                                                                                         \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}