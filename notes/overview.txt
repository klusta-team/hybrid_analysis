#Original data files
There is a folder consisting of the three recordings (.dat files) of Mariano Belluscio. One .dat file has been clustered (`n6mab031109.dat`), with method `MKKdistfloat` and has a number of nice clusters out of which we can choose a few suitable donor cells. 

#Hybrid dataset creation

Minimal information necessary for defining a hybrid dataset is a 4-tuple of the form: $\mbox{(acceptor, donor_id, amplitude, time_series)}$, where `acceptor` is the dataset which receives spikes from another analogously recorded dataset `donor` at the times specified by `time_series`.
Each element of the 4-tuple may be generated by a range of other parameters, e.g.

1) A rate, $r$ could define a `time_series` consisting of regular spiking at $r$ Hz.

2) The donor_id could be derived from information, e.g. the 3-tuple $\mbox{(donor,donorcluid,donorcluster)}$ pertaining to the donor dataset (donor), the detection method and clustering algorithm (donorcluid) and cluster (donorcluster) number of the cell that is added to the acceptor dataset.
    def: create_donor_id(donor,donorcluid,donorcluster):
    
    output: 
    donor_id = donor_donorcluid_donorcluster, (which typically looks like: `n6mab031109_MKKdistfloat_54`).
    meanspike_file_id = a file called donor_id.msua.1
    meanmask_file = a file called donor_id.amsk.1
    
We can have a folder containing donor_ids, or a list of 3-tuples generating to donor_ids.   
    
We can create a hybrid dataset $D_{\mbox{(acceptor, donor_id, amplitude, time_series)}}$ using the Python function:
    def: create_hybrid_datfile(acceptor, donor_id, amplitude, time_series):
        
This function outputs a raw datafile called, $\mathcal{H}_{\mbox{(acceptor, donor_id, amplitude, time_series)}}$.dat, where $\mathcal{H}_{\mbox{var}}$ is the hash produced from the variables `var` via some hash function.  

Question: The raw waveform from one recording on non-relevant channels could contain wildly inappropriate waveforms. I got around this before by only added parts of the wave form corresponding to the .amsk.1 file.    
    
#Running SpikeDetekt with various parameters

We aim to find the optimal detection strategy, but running spikedetekt on $\mathcal{H}_{\mbox{(acceptor, donor_id, amplitude, time_series)}}$.dat  several times using a variety of parameters, `params`, resulting in two files:

$\mathcal{H}_{\mbox{(acceptor, donor_id, amplitude, time_series)}}$_$\mathcal{H}_{\mbox{ params}}$.kwx 

$\mathcal{H}_{\mbox{(acceptor, donor_id, amplitude, time_series)}}$_$\mathcal{H}_{\mbox{ params}}$.kwik

The feature and mask vectors, corresponding to the .fet and .fmask files are stored in the .kwx file, these will later be required by Masked KlustaKwik.

The parameters are stored in a global Python dictionary of  variables which can be accessed by all modules of SpikeDetekt.
The default value of these parameters are stored in `spikedetekt/spikedetekt/defaultparameters.py`. 

We would like t



